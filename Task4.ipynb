{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\wongy\\OneDrive\\Desktop\\School\\Y2S2\\INF2006_CloudComputing\\Assignment\\INF2006-Assignment-2\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "\n",
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "import pyspark.sql.functions as F\n",
    "from load_clean_data import load_clean_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a SparkSession\n",
    "spark = SparkSession.builder.appName(\"Task4\").getOrCreate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "df = load_clean_data(\"./data\", spark)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by channel and calculate the mean and median of the trusting points\n",
    "df_grouped = df.groupBy(\"_channel\").agg(\n",
    "    F.mean(\"_trust\").alias(\"mean_trusting_points\"),\n",
    "    F.median(\"_trust\").alias(\"median_trusting_points\")\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+--------------------+----------------------+\n",
      "|_channel        |mean_trusting_points|median_trusting_points|\n",
      "+----------------+--------------------+----------------------+\n",
      "|prizeplank      |1.0                 |1.0                   |\n",
      "|instagc         |0.9086886074429764  |0.9259                |\n",
      "|bitcoinget      |0.9577211864406794  |0.9615                |\n",
      "|tremorgames     |0.8287998293970339  |0.8108                |\n",
      "|coinworker      |0.8390619450317137  |0.8571                |\n",
      "|keeprewarding   |0.866699999999999   |0.8667                |\n",
      "|inboxpounds     |0.9375              |0.9375                |\n",
      "|neodev          |0.8399505561040375  |0.8378                |\n",
      "|zoombucks       |0.9283105102818009  |0.9189                |\n",
      "|cotter          |0.9188999999999999  |0.9189                |\n",
      "|surveymad       |0.8474142857142861  |0.8182                |\n",
      "|tasks4dollars   |0.8106617647058824  |0.8125                |\n",
      "|globalactioncash|0.7999999999999998  |0.8                   |\n",
      "|vivatic         |0.837799999999998   |0.8378                |\n",
      "|rewards1        |0.875               |0.875                 |\n",
      "|getpaid         |0.9235074626865674  |0.875                 |\n",
      "|clixsense       |0.8446473740795458  |0.85                  |\n",
      "|prodege         |0.8891299380492768  |0.8649                |\n",
      "|diamondtask     |0.7000000000000002  |0.7                   |\n",
      "|gifthunterclub  |0.855651635111873   |0.875                 |\n",
      "|prizerebel      |0.945899999999997   |0.9459                |\n",
      "|eup_slw         |0.6999999999999998  |0.7                   |\n",
      "|memolink        |0.9655000000000012  |0.9655                |\n",
      "|task_ph         |0.8649000000000032  |0.8649                |\n",
      "|sharecashgpt    |0.9189000000000002  |0.9189                |\n",
      "|elite           |0.8676844923326285  |0.8571                |\n",
      "+----------------+--------------------+----------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Show the results\n",
    "df_grouped.show(df_grouped.count(), False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code below this point is testing for Task 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+--------------------------------------------------+\n",
      "|airline       |top_5_reasons                                     |\n",
      "+--------------+--------------------------------------------------+\n",
      "|Delta         |[CSProblem, late, canttell, cancel, lostluggae]   |\n",
      "|Virgin America|[CSProblem, canttell, booking, badflight, cancel] |\n",
      "|United        |[CSProblem, late, canttell, cancel, lostluggae]   |\n",
      "|US Airways    |[CSProblem, late, canttell, cancel, lostluggae]   |\n",
      "|Southwest     |[CSProblem, cancel, badflight, canttell, late]    |\n",
      "|American      |[CSProblem, late, cancel, canttell, airplanestaff]|\n",
      "+--------------+--------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.types import ArrayType, StringType\n",
    "\n",
    "# replicating task 2\n",
    "def top_n_reasons(reasons, counts, n=5):\n",
    "    return [reason for reason, count in sorted(zip(reasons, counts), key=lambda x: x[1], reverse=True)[:n]]\n",
    "\n",
    "df_non_unknown = df.filter((F.col(\"airline\").isNotNull()) & (F.col(\"airline\") != \"NULL\") & (F.col(\"negativereason1\").isNotNull()) & (F.col(\"negativereason1\") != \"Unknown\"))\n",
    "top_n_udf = F.udf(top_n_reasons, ArrayType(StringType()))\n",
    "\n",
    "top_neg_reasons = df_non_unknown.groupBy('airline', 'negativereason1') \\\n",
    "    .agg(F.count('negativereason1').alias('reason_count'))\n",
    "\n",
    "# Group by airline again to collect all reasons and counts into lists\n",
    "airline_reasons = top_neg_reasons.groupBy('airline') \\\n",
    "    .agg(F.collect_list('negativereason1').alias('all_reasons'), \n",
    "         F.collect_list('reason_count').alias('all_counts'))\n",
    "\n",
    "# top 5 reasons for each airline\n",
    "top_5_neg_reasons = airline_reasons.withColumn('top_5_reasons', top_n_udf('all_reasons', 'all_counts'))\n",
    "\n",
    "top_5_neg_reasons.select('airline', 'top_5_reasons').show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
